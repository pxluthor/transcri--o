# c칩digo funcional trazendo a transcri칞칚o junto pela groq

import os
import streamlit as st
import toml
from pathlib import Path
import pyaudio
from st_audiorec import st_audiorec
import streamlit.components.v1 as components
from pydub import AudioSegment
from groq import Groq
import speech_recognition as sr

#config = toml.load("config.toml")

# Carregar a chave de API diretamente do arquivo de configura칞칚o
#api_key = st.secrets['api_keys']['groq'] 
#client = Groq(api_key=api_key)

api_key = "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"
client = Groq(api_key=api_key)
model = 'whisper-large-v3'


# fun칞칚o para dividir o audio 
def split_audio(filepath, chunk_length_ms=180000):
    """Dividir o arquivo de 치udio em partes menores."""
    audio = AudioSegment.from_file(filepath)
    chunks = [audio[i:i + chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]
    return chunks
#transcri칞칚o
def audio_chunk_to_text(chunk, model, client):
    """Converter um peda칞o de 치udio em texto usando o modelo de transcri칞칚o."""
    temp_filename = "temp_chunk.mp3"
    chunk.export(temp_filename, format="mp3")
    with open(temp_filename, "rb") as file:
        translation = client.audio.transcriptions.create(
            file=(temp_filename, file.read()),
            model=model,
            
        )

    os.remove(temp_filename)  # Remove o arquivo tempor치rio
    return translation.text

def transcribe_audio(filepath, model, client):
    """Transcrever todo o 치udio dividindo-o em partes menores."""
    chunks = split_audio(filepath)
    full_transcription = ""
    for i, chunk in enumerate(chunks):
        st.write(f"Transcrevendo parte {i + 1} de {len(chunks)}...")
        text = audio_chunk_to_text(chunk, model, client)
        full_transcription += text + " \n"
    return full_transcription.strip()

# Fun칞칚o para converter o papel de parede
def role_to_streamlit(role):
    return "assistente" if role == "model" else role

# Fun칞칚o principal
def main():
    #components.iframe("https://typebot_view.pxluthor.com.br/l-e-s-t-e-linear-6ezuy34", height=600)
    st.title("游눫 Chat - Transcription audio 游꿏游댈")

    # Sidebar
    with st.sidebar:
        st.title("Grava칞칚o de 츼udio")
        wav_audio_data = st_audiorec()
        st.divider()
        st.button("Limpar Chat", on_click=limpar_chat)

    # Inicializa칞칚o do chat
    if "chat" not in st.session_state:
        st.session_state.chat = []

    # Exibir hist칩rico do chat
    for message in st.session_state.chat:
        with st.chat_message(role_to_streamlit(message['role'])):
            st.markdown(message['text'])

    # Op칞칫es de entrada: texto ou 치udio
    opcao_entrada = st.sidebar.radio("Selecione o tipo de entrada:", ("Texto", "츼udio"))

    if opcao_entrada == "Texto":
        # ... C칩digo para entrada de texto existente ...
        if prompt := st.chat_input("Como posso ajudar?",): 
            st.session_state.chat.append({"role": "user", "text": prompt})
            # Ajuste conforme a integra칞칚o do modelo
            response = client.chat.completions.create(
                messages=[
                    {"role": "user", "content": prompt}
                ],
                model="llama3-8b-8192"
            )
            response_text = response.choices[0].message.content
            with st.chat_message("assistente"):
                st.markdown(response_text) 
                st.session_state.chat.append({"role": "assistente", "text": response_text})

    else:
        # ... C칩digo para entrada de 치udio existente ...
        arquivo_carregado = st.file_uploader("Carregar arquivo de 치udio (MP3 ou WAV)")
        st.chat_input("Como posso ajudar?")
        if arquivo_carregado:
            # Use st.cache_data para armazenar o arquivo em cache no diret칩rio do Streamlit
            st.audio("audio_temp.mp3", format="audio/mpeg", loop=False)
            @st.cache_data
            def carregar_audio(arquivo_carregado):
                return arquivo_carregado.read()

            audio_data = carregar_audio(arquivo_carregado)
            with open("audio_temp.mp3", "wb") as f:
                f.write(audio_data)

            st.info("Audio carregado !")

            if st.button("Fazer transcri칞칚o"):
                # Use o caminho do arquivo em st.session_state
                st.session_state.file_path = "audio_temp.mp3"
                transcription = transcribe_audio(st.session_state.file_path, model, client)
                st.session_state.chat.append({"role": "user", "text": f"ajuste a transcri칞칚o intercalando os interlocutores na timeline, traga o hor치rio da mensagem {transcription}"})
                with st.chat_message("assistente"):
                    st.success('Transcri칞칚o realizada')
                    st.markdown(transcription)

# Fun칞칚o para limpar o chat
def limpar_chat():
    st.session_state.chat = []
    if os.path.exists("audio_temp.mp3"):
        os.remove("audio_temp.mp3")

if __name__ == "__main__":
    main()
